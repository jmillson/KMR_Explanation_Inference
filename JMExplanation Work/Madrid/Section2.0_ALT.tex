%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
%
\RequirePackage{fix-cm}

\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathptmx}
%\usepackage{newtxtext,newtxmath}
\let\proof\relax
\let\endproof\relax
%\usepackage{amsthm}
%\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{times}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{bussproofs}
\usepackage{pgf}
\usepackage{adjustbox}
\usepackage{xcolor}
%\spnewtheorem{Pat}{Pat}{\bf}{\rm}


\DeclareMathSymbol{\Gamma}{\mathalpha}{operators}{0}
\DeclareMathSymbol{\Delta}{\mathalpha}{operators}{1}
\DeclareMathSymbol{\Theta}{\mathalpha}{operators}{2}
\DeclareMathSymbol{\Lambda}{\mathalpha}{operators}{3}
\DeclareMathSymbol{\Xi}{\mathalpha}{operators}{4}
\DeclareMathSymbol{\Pi}{\mathalpha}{operators}{5}
\DeclareMathSymbol{\Sigma}{\mathalpha}{operators}{6}
\DeclareMathSymbol{\Upsilon}{\mathalpha}{operators}{7}
\DeclareMathSymbol{\Phi}{\mathalpha}{operators}{8}
\DeclareMathSymbol{\Psi}{\mathalpha}{operators}{9}
\DeclareMathSymbol{\Omega}{\mathalpha}{operators}{10}


\DeclareFontFamily{U} {MnSymbolA}{}

\DeclareFontShape{U}{MnSymbolA}{m}{n}{
  <-6> MnSymbolA5
  <6-7> MnSymbolA6
  <7-8> MnSymbolA7
  <8-9> MnSymbolA8
  <9-10> MnSymbolA9
  <10-12> MnSymbolA10
  <12-> MnSymbolA12}{}
\DeclareFontShape{U}{MnSymbolA}{b}{n}{
  <-6> MnSymbolA-Bold5
  <6-7> MnSymbolA-Bold6
  <7-8> MnSymbolA-Bold7
  <8-9> MnSymbolA-Bold8
  <9-10> MnSymbolA-Bold9
  <10-12> MnSymbolA-Bold10
  <12-> MnSymbolA-Bold12}{}

\DeclareSymbolFont{MnSyA}{U}{MnSymbolA}{m}{n}

\DeclareMathSymbol{\twoheaduparrow}{\mathop}{MnSyA}{25}




\makeatletter

% % % % % % % % % % % % % % % Internal Commands % % % % % % % % % % % % %
\newcommand{\raisemath}[1]{\mathpalette{\raisem@th{#1}}}
\newcommand{\raisem@th}[3]{\raisebox{#1}{$#2#3$}}

\newcommand{\bigperpp}{%
  \mathop{\mathpalette\bigp@rpp\relax}%
  \displaylimits
}
\newcommand{\bigp@rpp}[2]{%
  \vcenter{
    \m@th\hbox{\scalebox{\ifx#1\displaystyle1.3\else1.3\fi}{$#1\perp$}}
  }%
}
\newcommand{\bigperp}{\raisemath{.5pt}{\bigperpp}}

\newcommand{\nm}{\,\mid\!\sim\,}
\newcommand{\ssim}{% 
     \setbox0=\hbox{$\sim$}%
     \adjustbox{width=8pt,height=\height}{$\sim$}
}


\newcommand{\Uuparrow}{% 
     \setbox0=\hbox{$\scriptstyle\Uparrow$}%\parbox[<alignment>][<height>][<inner arrangement>]{<width>}{<text>}
     \raisebox{.2ex}{$\scriptstyle\Uparrow$}
}
\newcommand{\uuparrow}{% 
     \setbox0=\hbox{$\scriptstyle\uparrow$}%
     \raisebox{.2ex}[5pt]{$\scriptstyle\uparrow$}
}
\newcommand{\thuarrow}{% 
     \setbox0=\hbox{$\scriptstyle\twoheaduparrow$}%
     \raisebox{.2ex}{$\scriptstyle\twoheaduparrow$}
}
% % % % % % % % % % % % some superscript commands (dont use often) % % % % % % % %
%\newcommand{\uw}[1]{{#1}^{\!\scriptscriptstyle\uparrow W}}
%\newcommand{\uww}[1]{{#1}^{\!\scriptscriptstyle\uparrow W'}}
%\newcommand{\uuw}[1]{{#1}^{\!\scriptscriptstyle\Uparrow W}}
%\newcommand{\uuww}[1]{{#1}^{\!\scriptscriptstyle\Uparrow W'}}
\newcommand{\dhu}[1]{{#1}^{\!\!\!\scriptstyle\twoheaduparrow}}

% % % % % COMMANDS FOR NON-MONOTONIC CONSEQUENCES % % % % % % % % %l
\newcommand{\nmc}{\mathbin{\mid\joinrel\!\!\ssim}}
\newcommand{\nme}{\mathrel{\nmc_{\!\!\!\!e\,}}}

\newcommand{\qmc}[4][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\!\uuparrow\scriptstyle #4}\,\,#3}
\newcommand{\nqmc}[4][\Gamma,]{{#1#2\mathrel{\not\nmc}}^{\!\!\!\!\!\!\!\uuparrow\scriptstyle #4}\,\,#3}
\newcommand{\mqmc}[3][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\uuparrow}\,\,#3}
\newcommand{\src}[4][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\!\Uuparrow\scriptstyle #4}\,\,#3}
\newcommand{\gsrc}[3][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\thuarrow}\,\,#3}
\newcommand{\gsrce}[3][\Gamma,]{#1#2\,\,\mathrel{\nme}^{\!\!\!\!\!\!\!\!\thuarrow\,\,}\,#3}
\newcommand{\ngsrc}[3][\Gamma,]{{#1#2\,\,\mathrel{\not\nmc}}^{\!\!\!\!\!\thuarrow\scriptstyle}\,\,#3}


% % % % % % % % % % % % % % % % % Incomaptibility Set % % % % % % % % % % % % %
\newcommand{\Bigtheta}{% 
     \setbox0=\hbox{$\Theta$}%
     \scalebox{1.4}{$\Theta$}
}

\newcommand{\sris}[2]{\raisemath{-.5ex}{\Bigtheta}^{\!\!\raisemath{2pt}{\scriptscriptstyle #1}}_{\!\!\raisemath{-2pt}{\,\scriptscriptstyle #2\,}}} 

% % % % % % Degree Command % % % % % % % % % % % % % % % % % % % %
\newcommand{\degree}{\ensuremath{^\circ}}


\renewcommand\vec{\mathaccent"017E}

\makeatother




\journalname{Synthese}
%\renewcommand{\@cite}[1]{#1}
%\usepackage[natbibapa]{apacite}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage[hidelinks]{hyperref}
%\usepackage{lingmacros}
\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}
\newcommand\pref[1]{(\ref{#1})}

\setcitestyle{aysep={}, notesep=:}


\begin{document}

\title{The New Explanatory Inferentialism%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Kareem Khalifa        \and
        Jared Millson				\and
        Mark Risjord
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{Kareem Khalifa \at
              first address \\
              Tel.: +123-45-678910\\
              Fax: +123-45-678910\\
              \email{fauthor@example.com}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           Jared Millson \at
              second address
           \and 
           Mark Risjord \at
              third address
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor
\raggedbottom

\maketitle

\begin{abstract}
Abstract
\end{abstract}




\section{A New Approach to Explanatory Inferentialism}
\label{kernel}

The most dramatic way in which our approach to EI differs from that of Hempel and Kitcher is in our conception of \textit{inference} itself. For the latter, \textit{inference} is fundamentally a relation between sentences in a language. For us, it is a  practical concept. First and foremost, \textit{inference} characterizes something that we \textit{do}; its reference to a sentential relation or function is derivative. The idea that drawing inferences is one of, if not \textit{the} essential ways in which we use language is central to the approach of semantic inferentialism pioneered by Wilfrid Sellars and developed in detail by figures such as Robert Brandom and Jaroslav Peregrin. According to semantic inferentialism, the making of inferences is part of rule-governed practice---what Brandom calls, `a game of giving and asking for reasons.' In this game or practice, speakers are both players (making assertions and drawing inferences) and referees (keeping track of others' assertions and determining whether they are observing the rules of inference). But unlike other games, like \textit{Chess} or \textit{Simon Says}, the rules for the inference-game are not available to players as explicit instructions. Rather, the propriety of inferential moves is exhibited by the way other participants respond to those that make them. In this sense, the rules governing the game ---i.e. the rules of inference--- are \textit{implicit} in the practice of playing it. It is only because locutions can be introduced that permit speakers to explicitly endorse inferential moves that the notion of \textit{inference} as a relation among sentences can have any purchase.




Traditional EI is of a piece with the classical project of analysis that animated Anglo-American philosophy for much of the twentieth century. In its most general sense, that project sought to show that the meanings expressed by one class of locutions could be expressed by another, more familiar, epistemologically secure, or semantically autonomous class of locutions. $\qmc{A}{B}{W}$ Hempel's account of explanation, for instance, aims to show how the meaning expressed by a class of explanatory locutions.  $\qmc{}{}{}%{\mathcal{P}(\mathcal{L})}$ ---i.e. indicative sentences containing the predicates ``\ldots explains\ldots,'' ``\ldots is a potential explanation of\ldots,'' ``\ldots is an adequate explanation of\ldots'' etc. as well as certain why-interrogative sentences---can be expressed by inferences among sentences belonging to a model language consisting of names for physical objects or spatio-temporal locations and so-called `qualitative' predicates. In contrast, our approach attempts to demonstrate that locutions such as``\ldots best explains \ldots'' enable speakers to \textit{say} something that they could otherwise only \textit{do}, in particular, to overtly \textit{endorse} inferences that they could otherwise---i.e. using a non-explanatory language---only \textit{make}.\footnote{In this sense, our approach to explanatory vocabulary is a contribution to the program of analytic pragmatism described by \cite{Brandom2008}. } This is what we mean when we say that explanatory vocabulary makes explicit inferential commitments.

For us, explanatory vocabulary makes explicit commitments to certain patterns of \textit{material} inference. Unlike the inferences codified by formal logic, material inferences are those whose correctness is not determined by the meaning and arrangement of logical terms---i.e. their `logical form'. The inference from ``Boston is north of Atlanta'' to ``Atlanta is south of Boston'' is an example of a good material inference. The formalist's insistence that this inference is enthymematic until the suppressed premise ``If x is north of y, then y is south of x'' is added simply trades the goodness of the material inference for the truth of the conditional. On our view, the inference is good as it stands, and the supposedly `suppressed' conditional is a way of making commitment to that inference explicit. 

The class of material inferences with which we are concerned consist of those that preserve \textit{entitlement} such that if one is entitled to (assert) the premises, then one is entitled to (assert) the conclusion. Such inferences are distinctly \textit{non-monotonic}. Ordinary scientific practice is replete with them---e.g. ``The liquid is acidic. So, it will turn blue litmus paper red.'' A good material inference of this sort might turn bad if additional premises or auxiliary hypotheses were added---e.g. ``Chlorine gas is present''\footnote{Chlorine gas bleaches damp litmus paper.}---and likewise, a bad inference might be made good by adding the right premises.

It is precisely because entitlement-preserving material inferences are non-monotonic that mastery of them requires an ability to discriminate between those hypothetical circumstances in which they would remain good and those in which they would not.  After all, there are many pieces of additional information which would leave the propriety of our acid inference untouched---e.g. if the litmus paper \textit{were} soaked for two minutes, if the person dipping the paper \textit{were} wearing an orange shirt, if the test \textit{were} conducted in Romania, etc. Our emphasis in each of these suppositions is intended to draw attention to the fact that they are most naturally expressed using the subjunctive form of the verb \textit{to be} and, consequently, that they each suppose possible states of affairs.\footnote{We permit these suppositions to denote both contrary-to-fact and non-contrary-to-fact states of affairs. See note \ref{Grammar} below.} Thus, the material inferences with which we are presently concerned exhibit some degree of \textit{subjunctive stability} in the sense that for any particular, correct inference there are sets of suppositions under which its propriety would remain unchanged and complementary sets of suppositions under which it would not.\footnote{\label{Grammar}The English conditional ``If P were the case, then Q would be the case''  is formed with the subjunctive mood. Such sentences are sometimes called \textit{counterfactual} conditionals. Other times, they are \textit{distinguished} from counterfactual conditionals, which are identified with sentences of the form `If P had been the case, then Q would have been the case.' In many languages, the antecedent of the latter sentence would be formulated in the past subjunctive, however, since English lacks a past subjunctive, the antecedent appears in the indicative mood with an extra layer of past tense morphology. We will use the term \textit{subjunctive} to pick out clauses of either type. In doing so, we reject the putative contrast between the two which claims that properly `counterfactual' conditionals presuppose that their antecedent is false, while simple `subjunctive' conditionals do not. As the following sentence shows, this is not always the case: ``If Susan had contracted influenza, then she would have presented exactly the symptoms that she does.''}  

In order to perspicuously represent the subjunctive stability of material inferences, let's introduce a formal structure with a non-monotonic material consequence relation defined over a finite language, $ \mathcal{L}_{0} $, consisting of atomic sentences $ p, p_1, p_2, \ldots, p_n$. $ \Gamma, \Delta, \Theta $ are sets of sentences and $ W, W',W'' $ sets of sets of sentences. We reserve the uppercase Latin letters, $ A, B, C, D $ for sentence variables. In order to represent material incoherence, we extend $ \mathcal{L}_0 $ to include the constant $ \bigperp $, i.e. $ \mathcal{L} $ = $ \mathcal{L}_0 \,\bigcup \,\{\bigperp\}$. \footnote{We stipulate that $ \bigperp $ can neither appear to the left of the turnstile nor be embedded, i.e. $ {\nmc} \subseteq \mathcal{P}(\mathcal{L}_0) \times \mathcal{L} $.} We define $ \nmc $ as the relation over $ \mathcal{L} $ such that $  \Gamma\nmc A $ iff  $\Gamma$ materially implies $ A $, and $\Gamma\nmc \bigperp $ iff $ \Gamma $ is materially incoherent. 

We now have in place an object language $ \mathcal{L} $ (an extension of  $ \mathcal{L}_0 $ that includes $ \bigperp $) and a meta-language that consists of $ \nmc $.  In the appendix, we formulate and explain the properties of the structure $ \langle \mathcal{L}, \nmc \rangle  $. For present purposes we simply note that $ \nmc $ is non-monotonic and non-transitive.  The most basic inferences with which we will be interested are of the form $ \Gamma, A \nmc B $.  We read this expression as stating that anyone who is committed and entitled to A in context $ \Gamma $ is entitled to B. Similarly, we read  $\Gamma, A, B \nmc \bigperp $ as stating that in context $ \Gamma $, commitment and entitlement to A  precludes entitlement to B and vice versa.\footnote{Note that the comma is to be read as set-union with flanking individual formulas being read as in set brackets; e.g. ``$ A $'' on the left means ``$ \{ A\} $''.}  We reserve $ \Gamma $ exclusively for a (non-empty) set of collateral commitments intended to represent the epistemic context of inference. As such, we assume that $ \Gamma $ contains information about, e.g., the experimental set-up, background knowledge relevant to the system in question, etc. \textcolor{red}{more}, but does not contain the agent's total knowledge of the world. 

We're now in a position to provide a formal representation of subjunctive stability. To do so, we simply quantify over our material consequence relation, $ \nmc $. \newline

\noindent\textbf{Quantified Material Consequence (QMC):}
		\begin{equation}
              \qmc{A}{B}{W} \Longleftrightarrow_{df}
				      \begin{cases}\nonumber
				        1.\,\, W\subseteq\mathcal{P}(\mathcal{L}) & $ and $ \\[3pt] 
						2.\,\, \forall\Delta\in W(\Gamma, A,  \Delta \nmc B ) 
						\end{cases}
		\end{equation}
		
With this definition we now have a handy way of talking about \textit{sets} of material inferences. Note that since $ \emptyset \in W $, our set must include $ \Gamma, A \nmc B $. Call this the \textit{base inference} of the set of inferences. Sets of inferences are delimited by the set of sets of sentences of $ \mathcal{L} $ whose members may be added to the premises without impugning the base inference. The resulting set thus contains $ |W| $ many inferences,  and when $ W = \mathcal{P}(\mathcal{L}) $, the consequence relation in $\qmc{A}{B}{W} $ is globally monotonic. When this is the case, we write $ \mqmc[]{}{} $  rather than $ \qmc[]{}{}{ \mathcal{P}(\mathcal{L}) }$.\footnote{The reason for circumscribing these sets of inferences by subsets of $ \mathcal{P}(\mathcal{L}) $ is that atomic sentences that would, by themselves materially defeat an inference if added to the premises, need not defeat that inference if they are add along with other atomic sentences. For instance, our inference from ``The match is struck'' to ``The match will light'' will be defeated by the singleton \{``The match is in a strong magnetic field''\}       but not by the set \{``The match is in a strong magnetic field'', ``The match is struck inside a Faraday cage''\}.} We may treat $ \qmc{A}{B}{W}  $ as saying that the (base) inference from $ A $ to $ B $ \textit{would} remain materially good for an agent in context $ \Gamma $ even if she \textit{were} to undertake sets of collateral commitments from $ W $. Thus, we have a formal representation of the stability of a material inference under a set of subjunctive suppositions, $W$.\footnote{For ease of exposition we refer to $W$ as a set of suppositions, even though it is technically a set of sets of sentences in $\mathcal{L}_0$.}

While there are many sets of subjunctive suppositions under which the propriety of any particular material inference might persist, there must be some superset that includes all the members of those sets. This superset represents the furthest extent of the inference's subjunctive stability; we can think of it as the inference's `island of monotonicity,' since it contains all those suppositions whose addition to the premises would not undermine the inference. When we wish to distinguish material inferences (or the consequence relations that represent them) by reference to their full range of subjunctive stability, we will refer to them as \textit{sturdy} inferences. 

Here is our formal definition of sturdy inference. (For the remaining meta-theoretical claims, we omit reference to $\mathcal{L}$ and $\mathcal{P}(\mathcal{L})$ whenever doing so will not mislead the reader.) \newline

\noindent\textbf{Sturdy Material Consequence (SMC):}
		  \begin{equation}
		      \src{A}{B}{W}\Longleftrightarrow_{df}
		      \begin{cases}\nonumber
		        1.\,\, \qmc{A}{B}{W}& $ and $ \\[3pt] 
				2.\,\, \forall W'(\qmc{A}{B}{W'}\Longrightarrow W' \subseteq W)  & $ and $\\[3pt] 
				3.\,\, \nqmc[]{\Gamma}{B}{W} & $ and $\\[3pt]  
		        4.\,\, \forall\Delta(\mqmc{A, \Delta}{\bigperp}\Longrightarrow \Delta \not\in W)

				\end{cases}
		  \end{equation}


The first condition of SMC tells us that the base inference $ \Gamma, A \nmc B $ would be licensed if any of the members of  $W$ were to be added to its premise-set, but the second condition says that $W$ contains \textit{all} those sets of sentences whose addition would not defeat the inference. The third condition prevents the conclusion from simply following from the context alone, while the fourth condition prohibits the elements of $W$ from being logically inconsistent with the premises, thereby ensuring that the conclusion follows non-trivially.\footnote{If SMC4 were not present, $B$ could follow by \textit{Ex Falso Fixo Quodlibet}. See Appendix.}  When the consequence relation $ \src[]{}{}{W} $ holds, we say that the base inference is \textit{sturdy up to} $ W $.  




\subsection{The Nature of Explanatory Inferences}

\textcolor{red}{I'm thinking that this section will contain both a motivation of our conception of explanatory inferences and the formal definition and the Simmelweiss examples to illustrate.}
It is our contention that properly \textit{explanatory} inferences form a neatly circumscribed class of sturdy inferences and that it is commitment to these inferences that locutions such as  \textit{best explains} make explicit.


On our view, explanatory inferences are distinguished from other types of `locally monotonic' material inferences by two characteristics. First, the (non-contextual) premises of explanatory inferences imply their conclusion with greater subjunctive robustness than any other premises that materially imply that conclusion (in the same context). In other words, the maximal set of subjunctive suppositions that can hold without defeating an explanatory inference is greater than that of any other material inference that has the same conclusion. Call this characteristic \textit{Superlative Robustness}. Second, the premises of explanatory inferences are `difference makers' in the sense that if the content of the latter were different, the content of the conclusion would be different as well. If, for instance, any sentence incompatible with the premises of a good explanatory inference were substituted for those premises, then the inference should yield something incompatible with the (original) conclusion.   Call this the \textit{Difference Maker} characteristic. \footnote{We view these characteristics as independently necessary but not jointly sufficient conditions for an explanatory inference. There is at least one more necessary condition that is required for an adequate analysis, namely, that explanatory inferences support the patterns of reasoning  known as Inference-to-the-Best-Explanation. Since this characteristic is orthogonal to the issues raised by the symmetry problem, we have omitted it from the present discussion.} 


With SMC, we now have the means by which to compare the stability of material inferences that share the same conclusion. This means that we can identify those premises that materially imply a specified conclusion with the greatest subjective stability, thereby capturing the \textit{Superlative Stability} characteristic of explanatory inferences set out above. In order to represent \textit{Difference Making}, however, we need a way to specify the sets of sentences that are incompatible with a particular sentence, $A$, in a particular context, $\Gamma$,  under a set of subjunctive suppositions, $W$. For this, we have QIS.\newline

\noindent\textbf{Quantified Incompatibility Set (QIS):} \hspace{3mm}$ D \in \sris{W}{\Gamma,\,A} \Longleftrightarrow_{df} \,\,\,\qmc{A, D}{\bigperp}{W} $
\newline

The set $  \sris{W}{\Gamma,\,A}  $contains all those formulas that are incompatible with $A$ in context $ \Gamma $ and that would continue to produce materially incoherence were any of the members of $W$ added to it. This definition provides the resources with which to express \textit{Difference Making}. We do so in the third condition of following definition.\newline

\noindent\textbf{Maximally Sturdy Material Consequence (MSMC):}
		\begin{equation}
		   \gsrc{A}{\,B} \Longleftrightarrow_{df} 
		    \begin{cases}\nonumber 
			      1.\,\, \src{A}{B}{W} & $ and $ \\[3pt] 
				  2.\,\, \forall C(C \neq B)\,(\src{C}{B}{W'}\Longrightarrow W'\subseteq W ) & $ and $ \\[3pt] 
				  3.\,\, (\forall D_{\scriptscriptstyle A} \in \sris{W}{\Gamma,\,A}) (\exists!D_{\scriptscriptstyle B} \in \sris{W}{\Gamma,\,B})(\qmc{D_{\scriptscriptstyle A}}{D_{\scriptscriptstyle B}}{W})
			 \end{cases}
		\end{equation}


The MSMC relation is our meta-language expression for explanatory inference. The first condition says that the base inference is sturdy under $W$. The second condition tells us that $W$ is the largest set of subjunctive suppositions under which any sentence from $\mathcal{L}$ materially implies $B$, excluding $B$ itself. For this reason $W $ need not appear on the left-side of the definition. If we think of $ A $ as providing the best explanation of $ B $ and of $ C $ as any less-than-best explanation, then the second condition says that the best explanation is stable under more subjunctive suppositions than any of its suboptimal competitors. The third condition informs us that if any claim incompatible with $A$ were to replace $A$ in the premises, then it would materially imply a unique claim incompatible with $B$, under the subjunctive suppositions in $W$. Since the negation of a sentence can be construed (in an extended language) in terms of quantification over the set of sentences incompatible with that sentence, the third condition entails that if $A$ were not the case, $B$ would not be the case. 

\textcolor{red}{Need a bit more...}


\section{Appendix}


We use a meta-theoretical conditional, $ \Longrightarrow $, to formulate the properties of the structure $ \langle \mathcal{L} \nmc \rangle $ as follows:\footnote{We restrict these claims to finite premise sets.}


\begin{enumerate}
\item $ \mathcal{L}_0\nmc\bigperp$
\item $ \emptyset\not\nmc\bigperp $
\item $ \forall p, \forall\Delta\subseteq\mathcal{L}_0(\Gamma, \Delta \nmc\bigperp \Longrightarrow \Gamma\nmc p) $ (Ex Falso Fixo Quodlibet)
\item $\forall \Gamma\subseteq\mathcal{L}_0 (\Delta \in \Gamma \Longrightarrow \Gamma\nmc \Delta)$ (Reflexivity)
\item $\forall\Delta\subseteq\mathcal{L}_0(\Gamma\nmc p \,\,\not\!\!\Longrightarrow \Gamma, \Delta \nmc p)$ (Non-monotonicity)
\item $(\Gamma\nmc p_j $ and $ \Gamma, p_j \nmc p_k ) \,\,\not\!\!\Longrightarrow \Gamma \nmc p_k$ (Non-transitivity)
\end{enumerate}

The first two properties state, respectively, that the totality of $ \mathcal{L} $ is incoherent and that the empty set is not. The principle of \textit{Ex Falso Fixo Quodlibet} is a modification of \textit{Ex Falso Quodlibet} that restricts `explosion' to monotonic contexts only. The rationale for this restriction is that if a set of atomic sentences is non-monotonically incoherent, then adding additional sentences to it may make it coherent, and therefore we are not licensed to infer an arbitrary atom from it (the original set). Reflexivity is a standard property of consequence relations and non-monotonicity has already been explained. 

The last property of the structure, however, is sure to surprise the reader. Nearly all consequence relations, including the standard non-monotonic ones, are transitive and include the Cut rule as a structural constraint. Nevertheless, as \cite{Morgan2000} has demonstrated,  a deduction theorem (i.e. $\Gamma, A \nmc B \Longleftrightarrow \Gamma \nmc A \rightarrow B $) cannot hold for a non-monotonic, reflexive, and transitive consequence relation.  The provability of a deduction theorem is essential to our inferentialist approach to logical vocabulary, since it establishes that an object-language operator gives expression to, i.e. makes explicit, what would be given as a rule of inference in the meta-language, i.e. using `$ \nmc $'. We have already motivated the non-monotonic character of material inference above. So, we must choose between  reflexivity and transitivity. 

There are some reasons to prefer a consequence relation that is reflexive but non-transitive. First, sets of explanatory statements often fail to license transitive inferences---e.g. the occurrence of the Big Bang does not explain why Adam ate the apple, even if there are true explanatory statements linking the Big Bang to event $E_1$, $ E_1 $ with $ E_2 $, and so on up to Adam's eating of the apple. Second, while an unrestricted reflexive consequence relation made explicit by the \textit{best explains} operator entails that a statement is the best explanation of itself, this unwanted result can be avoided by principled restrictions on the `scope' of the (quantified) consequence relation, as is done in MSMC2. In contrast, it is more difficult to a restrict transitivity in a manner that it is not \textit{ad hoc}. Third, logicians of the inferentialist and proof-theoretic approach have have already begun to explore systems in which Cut fails \citep{Ripley2011,Tennant2014}, whereas none seems inclined to pursue non-reflexive ones. Finally, reflexivity just seems to be a more ubiquitous feature of ordinary material inferences than transitivity does.

\bibliographystyle{plainnat}
\bibliography{Explanation_bib} 

% % % % % % % % % % % % % % % % % % % % % % % For submission use bib below and paste bibitems % % % % % % % % % % % % % % % % %
%\begin{thebibliography}{19}
%\providecommand{\natexlab}[1]{#1}
%\providecommand{\url}[1]{{#1}}
%\providecommand{\urlprefix}{URL }
%\expandafter\ifx\csname urlstyle\endcsname\relax
%  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
%  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
%  \urlstyle{rm}\Url}\fi
%\providecommand{\eprint}[2][]{\url{#2}}
%
%%\bibitem[{Goldberg(2011)}]{Goldberg2011}
%%Goldberg S (2011) Putting the norm of assertion to work: The case of testimony.
%%  In: Brown J, Cappelen H (eds) Assertion: New Philosophical Essays, Oxford
%%  University Press
%
%
%
%\end{thebibliography}

\end{document}