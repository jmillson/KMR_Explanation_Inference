%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
%
\RequirePackage{fix-cm}

\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathptmx}
%\usepackage{newtxtext,newtxmath}
\let\proof\relax
\let\endproof\relax
%\usepackage{amsthm}
%\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{times}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{bussproofs}
\usepackage{pgf}
\usepackage{adjustbox}
\usepackage{xcolor}



\DeclareMathSymbol{\Gamma}{\mathalpha}{operators}{0}
\DeclareMathSymbol{\Delta}{\mathalpha}{operators}{1}
\DeclareMathSymbol{\Theta}{\mathalpha}{operators}{2}
\DeclareMathSymbol{\Lambda}{\mathalpha}{operators}{3}
\DeclareMathSymbol{\Xi}{\mathalpha}{operators}{4}
\DeclareMathSymbol{\Pi}{\mathalpha}{operators}{5}
\DeclareMathSymbol{\Sigma}{\mathalpha}{operators}{6}
\DeclareMathSymbol{\Upsilon}{\mathalpha}{operators}{7}
\DeclareMathSymbol{\Phi}{\mathalpha}{operators}{8}
\DeclareMathSymbol{\Psi}{\mathalpha}{operators}{9}
\DeclareMathSymbol{\Omega}{\mathalpha}{operators}{10}


\DeclareFontFamily{U} {MnSymbolA}{}

\DeclareFontShape{U}{MnSymbolA}{m}{n}{
  <-6> MnSymbolA5
  <6-7> MnSymbolA6
  <7-8> MnSymbolA7
  <8-9> MnSymbolA8
  <9-10> MnSymbolA9
  <10-12> MnSymbolA10
  <12-> MnSymbolA12}{}
\DeclareFontShape{U}{MnSymbolA}{b}{n}{
  <-6> MnSymbolA-Bold5
  <6-7> MnSymbolA-Bold6
  <7-8> MnSymbolA-Bold7
  <8-9> MnSymbolA-Bold8
  <9-10> MnSymbolA-Bold9
  <10-12> MnSymbolA-Bold10
  <12-> MnSymbolA-Bold12}{}

\DeclareSymbolFont{MnSyA}{U}{MnSymbolA}{m}{n}

\DeclareMathSymbol{\twoheaduparrow}{\mathop}{MnSyA}{25}




\makeatletter

% % % % % % % % % % % % % % % Internal Commands % % % % % % % % % % % % %
\newcommand{\raisemath}[1]{\mathpalette{\raisem@th{#1}}}
\newcommand{\raisem@th}[3]{\raisebox{#1}{$#2#3$}}

\newcommand{\bigperpp}{%
  \mathop{\mathpalette\bigp@rpp\relax}%
  \displaylimits
}
\newcommand{\bigp@rpp}[2]{%
  \vcenter{
    \m@th\hbox{\scalebox{\ifx#1\displaystyle1.3\else1.3\fi}{$#1\perp$}}
  }%
}
\newcommand{\bigperp}{\raisemath{.5pt}{\bigperpp}}

\newcommand{\nm}{\,\mid\!\sim\,}
\newcommand{\ssim}{% 
     \setbox0=\hbox{$\sim$}%
     \adjustbox{width=8pt,height=\height}{$\sim$}
}
\newcommand{\Uuparrow}{% 
     \setbox0=\hbox{$\scriptstyle\Uparrow$}%
     \raisebox{.2ex}{$\scriptstyle\Uparrow$}
}
\newcommand{\uuparrow}{% 
     \setbox0=\hbox{$\scriptstyle\uparrow$}%
     \raisebox{.2ex}{$\scriptstyle\uparrow$}
}
\newcommand{\thuarrow}{% 
     \setbox0=\hbox{$\scriptstyle\twoheaduparrow$}%
     \raisebox{.2ex}{$\scriptstyle\twoheaduparrow$}
}
% % % % % % % % % % % % some superscript commands (dont use often) % % % % % % % %
%\newcommand{\uw}[1]{{#1}^{\!\scriptscriptstyle\uparrow W}}
%\newcommand{\uww}[1]{{#1}^{\!\scriptscriptstyle\uparrow W'}}
%\newcommand{\uuw}[1]{{#1}^{\!\scriptscriptstyle\Uparrow W}}
%\newcommand{\uuww}[1]{{#1}^{\!\scriptscriptstyle\Uparrow W'}}
\newcommand{\dhu}[1]{{#1}^{\!\!\!\scriptstyle\twoheaduparrow}}

% % % % % COMMANDS FOR NON-MONOTONIC CONSEQUENCES % % % % % % % % %l
\newcommand{\nmc}{\mathbin{\mid\joinrel\!\!\ssim}}
\newcommand{\nme}{\mathrel{\nmc_{\!\!\!\!e\,}}}

\newcommand{\qmc}[4][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\!\uuparrow\scriptstyle #4}\,\,#3}
\newcommand{\nqmc}[4][\Gamma,]{{#1#2\mathrel{\not\nmc}}^{\!\!\!\!\!\!\!\uuparrow\scriptstyle #4}\,\,#3}
\newcommand{\mqmc}[3][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\uuparrow}\,\,#3}
\newcommand{\src}[4][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\!\Uuparrow\scriptstyle #4}\,\,#3}
\newcommand{\gsrc}[3][\Gamma,]{{#1#2\,\,\mathrel{\nmc}}^{\!\!\!\!\!\!\thuarrow}\,\,#3}
\newcommand{\gsrce}[3][\Gamma,]{#1#2\,\,\mathrel{\nme}^{\!\!\!\!\!\!\!\!\thuarrow\,\,}\,#3}
\newcommand{\ngsrc}[3][\Gamma,]{{#1#2\,\,\mathrel{\not\nmc}}^{\!\!\!\!\!\thuarrow\scriptstyle}\,\,#3}


% % % % % % % % % % % % % % % % % Incomaptibility Set % % % % % % % % % % % % %
\newcommand{\Bigtheta}{% 
     \setbox0=\hbox{$\Theta$}%
     \scalebox{1.4}{$\Theta$}
}

\newcommand{\sris}[2]{\raisemath{-.5ex}{\Bigtheta}^{\!\!\raisemath{2pt}{\scriptscriptstyle #1}}_{\!\!\raisemath{-2pt}{\,\scriptscriptstyle #2\,}}} 

% % % % % % Degree Command % % % % % % % % % % % % % % % % % % % %
\newcommand{\degree}{\ensuremath{^\circ}}


\renewcommand\vec{\mathaccent"017E}

\makeatother




\journalname{Synthese}
%\renewcommand{\@cite}[1]{#1}
%\usepackage[natbibapa]{apacite}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage[hidelinks]{hyperref}
%\usepackage{lingmacros}
\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}
\newcommand\pref[1]{(\ref{#1})}

\setcitestyle{aysep={}, notesep=:}


\begin{document}

\title{The New Explanatory Inferentialism%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Kareem Khalifa        \and
        Jared Millson				\and
        Mark Risjord
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{Kareem Khalifa \at
              first address \\
              Tel.: +123-45-678910\\
              Fax: +123-45-678910\\
              \email{fauthor@example.com}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           Jared Millson \at
              second address
           \and 
           Mark Risjord \at
              third address
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor
\raggedbottom

\maketitle

\begin{abstract}
Abstract
\end{abstract}




\section{A New Approach to Explanatory Inferentialism}
\label{kernel}

The most dramatic way in which our approach to EI differs from that of Hempel and Kitcher is in our conception of \textit{inference} itself. For the latter, \textit{inference} is fundamentally a relation between sentences in a language. For us, it is a  practical concept. First and foremost, \textit{inference} characterizes something that we \textit{do}; its reference to a sentential relation or function is derivative. The idea that drawing inferences is one of, if not \textit{the} essential ways in which we use language is central to the approach of semantic inferentialism pioneered by Wilfrid Sellars and developed in detail by figures such as Robert Brandom and Jaroslav Peregrin. According to semantic inferentialism, the making of inferences is part of rule-governed practice---what Brandom calls, `a game of giving and asking for reasons.' In this game or practice, speakers are both players (making assertions and drawing inferences) and referees (keeping track of others' assertions and determining whether they are observing the rules of inference). But unlike other games, like \textit{Chess} or \textit{Simon Says}, the rules for the inference-game are not available to players as explicit instructions. Rather, the propriety of inferential moves is exhibited by the way other participants respond to those that make them. In this sense, the rules governing the game ---i.e. the rules of inference--- are \textit{implicit} in the practice of playing it. It is only because locutions can be introduced that permit speakers to explicitly endorse inferential moves that the notion of \textit{inference} as a relation among sentences can have any purchase.

Traditional EI is of a piece with the classical project of analysis that animated Anglo-American philosophy for much of the twentieth century. In its most general sense, that project sought to show that the meanings expressed by one class of locutions could be expressed by another, more familiar, epistemologically secure, or semantically autonomous class of locutions. Hempel's account of explanation, for instance, aims to show how the meaning expressed by a class of explanatory locutions---i.e. indicative sentences containing the predicates ``\ldots explains\ldots,'' ``\ldots is a potential explanation of\ldots,'' ``\ldots is an adequate explanation of\ldots'' etc. as well as certain why-interrogative sentences---can be expressed by inferences among sentences belonging to a model language consisting of names for physical objects or spatio-temporal locations and so-called `qualitative' predicates. In contrast, our approach attempts to demonstrate that locutions such as``\ldots best explains \ldots'' enable speakers to \textit{say} something that they could otherwise only \textit{do}, in particular, to overtly \textit{endorse} inferences that they could otherwise---i.e. using a non-explanatory language---only \textit{make}.\footnote{In this sense, our approach to explanatory vocabulary is a contribution to the program of analytic pragmatism described by \cite{Brandom2008}. } This is what we mean when we say that explanatory vocabulary makes explicit inferential commitments.

For us, explanatory vocabulary makes explicit commitments to certain patterns of \textit{material} inference. Unlike the inferences codified by formal logic, material inferences are those whose correctness is not determined by the meaning and arrangement of logical terms---i.e. their `logical form'. The inference from ``Boston is north of Atlanta'' to ``Atlanta is south of Boston'' is an example of a good material inference. The formalist's insistence that this inference is enthymematic until the suppressed premise ``If x is north of y, then y is south of x'' is added simply trades the goodness of the material inference for the truth of the conditional. On our view, the inference is good as it stands, and the supposedly `suppressed' conditional is a way of making commitment to that inference explicit. 

The class of material inferences with which we are concerned consist of those that preserve \textit{entitlement} such that if one is entitled to (assert) the premises, then one is entitled to (assert) the conclusion. Such inferences are distinctly \textit{non-monotonic}. Ordinary scientific practice is replete with them---e.g. ``The liquid is acidic. So, it will turn blue litmus paper red.'' A good material inference of this sort might turn bad if additional premises or auxiliary hypotheses were added---e.g. ``Chlorine gas is present''\footnote{Chlorine gas bleaches damp litmus paper.}---and likewise, a bad inference might be made good by adding the right premises.

It is precisely because entitlement-preserving material inferences are non-monotonic that mastery of them requires an ability to discriminate between those hypothetical circumstances in which they would remain good and those in which they would not.  After all, there are many pieces of additional information which would leave the propriety of our acid inference untouched---e.g. if the litmus paper \textit{were} soaked for two minutes, if the person dipping the paper \textit{were} wearing an orange shirt, if the test \textit{were} conducted in Romania, etc. Our emphasis in each of these suppositions is intended to draw attention to the fact that they are most naturally expressed using the subjunctive form of the verb \textit{to be} and, consequently, that they denote (merely) possible states-of-affairs.\footnote{We permit these suppositions to denote both actual (though unknown) and contrary-to-fact states of affairs. See note \ref{Grammar} below.} Thus, the material inferences with which we are presently concerned exhibit some degree of \textit{subjunctive stability} in the sense that for any particular, correct inference there are sets of suppositions under which its propriety would remain unchanged and complementary sets of suppositions under which it would not.\footnote{\label{Grammar}The English conditional ``If P were the case, then Q would be the case''  is formed with the subjunctive mood. Such sentences are sometimes called \textit{counterfactual} conditionals. Other times, they are \textit{distinguished} from counterfactual conditionals, which are identified with sentences of the form `If P had been the case, then Q would have been the case.' In many languages, the antecedent of the latter sentence would be formulated in the past subjunctive, however, since English lacks a past subjunctive, the antecedent appears in the indicative mood with an extra layer of past tense morphology. We will use the term \textit{subjunctive} to pick out clauses of either type. In doing so, we reject the putative contrast between the two which claims that properly `counterfactual' conditionals presuppose that their antecedent is false, while simple `subjunctive' conditionals do not. As the following sentence shows, this is not always the case: ``If Susan had contracted influenza, then she would have presented exactly the symptoms that she does.''}  

While there are many sets of subjunctive suppositions under which the propriety of any particular material inference might persist, there is some superset that includes all the members of those sets. This superset represents the furthest extent of the inference's subjunctive stability; we can think of it as the inference's `island of monotonicity,' since it contains all those sentences whose addition to the premise(s) would not undermine the inference. When we wish to distinguish material inferences (or the consequence relations that represent them) by reference to their full range of subjunctive stability, we will refer to them as \textit{sturdy} inferences. It is our contention that properly \textit{explanatory} inferences form a neatly circumscribed class of sturdy inferences and that it is commitment to these inferences that locutions such as  \textit{best explains} make explicit.


\subsection{The Nature of Explanatory Inferences}

\textcolor{red}{Placeholder}

On our view, explanatory inferences are distinguished from other types of `locally monotonic' material inferences by two characteristics. First, the (non-contextual) premises of explanatory inferences imply their conclusion with greater subjunctive robustness than any other premises that materially imply that conclusion (in the same context). In other words, the maximal set of subjunctive suppositions that can hold without defeating an explanatory inference is greater than that of any other material inference that has the same conclusion. Call this characteristic \textit{Superlative Robustness}. Second, the premises of explanatory inferences are `difference makers' in the sense that if the content of the latter were different, the content of the conclusion would be different as well. If, for instance, any sentence incompatible with the premises of a good explanatory inference were substituted for those premises, then the inference should yield something incompatible with the (original) conclusion.   Call this the \textit{Difference Maker} characteristic. \footnote{We view these characteristics as independently necessary but not jointly sufficient conditions for an explanatory inference. There is at least one more necessary condition that is required for an adequate analysis, namely, that explanatory inferences support the patterns of reasoning  known as Inference-to-the-Best-Explanation. Since this characteristic is orthogonal to the issues raised by the symmetry problem, we have omitted it from the present discussion.} 

\subsection{Representing Explanatory Inferences as Material Consequence Relations}

In order to perspicuously represent the defining characteristics of explanatory inference, we will construct a formal structure with a non-monotonic material consequence relation defined over a language of atomic sentences and proceed to circumscribe those instances of this relation that correspond to our explanatory inferences. We begin with a finite language $ \mathcal{L}_{0} $. Let $ p, p_1, p_2, $ etc. stand for atomic sentences, $ \Gamma, \Delta, \Theta $ for sets of atomic sentences, and $ W, W',W'' $ for sets of sets of atomic sentences. We reserve the uppercase Latin letters, $ A, B, C, D $ for formulas. In order to represent material incoherence, we extend $ \mathcal{L}_0 $ to include the constant $ \bigperp $, i.e. $ \mathcal{L} $ = $ \mathcal{L}_0 \,\bigcup \,\{\bigperp\}$. We further stipulate that $ \bigperp $ can neither appear to the left of the turnstile nor be embedded, i.e. $ {\nmc} \subseteq \mathcal{P}(\mathcal{L}_0) \times \mathcal{L} $. We can now define $ \nmc $ as the relation over $ \mathcal{L} $ such that $  \Gamma\nmc p $ iff  $\Gamma$ materially implies $ p $, and $\Gamma\nmc \bigperp $ iff $ \Gamma $ is materially incoherent. 

We have in place an object language $ \mathcal{L} $ (an extension of  $ \mathcal{L}_0 $ that includes $ \bigperp $) and a meta-language that consists of $ \nmc $.  In the appendix, we formulate and explain the properties of the structure $ \langle \mathcal{L}, \nmc \rangle  $. For present purposes we simply note that $ \nmc $ is non-monotonic and non-transitive.  The most basic inferences with which we will be interested are of the form $ \Gamma, A \nmc B $.  We read this expression as stating that anyone who is committed and entitled to A in context $ \Gamma $ is entitled to B. Similarly, we read  $\Gamma, A, B \nmc \bigperp $ as stating that in context $ \Gamma $, commitment and entitlement to A  precludes entitlement to B and vice versa.\footnote{Note that the comma is to be read as set-union with flanking individual formulas being read as in set brackets; e.g. ``$ A $'' on the left means ``$ \{ A\} $''.}  We reserve $ \Gamma $ exclusively for a (non-empty) set of collateral commitments intended to represent the epistemic context of inference. As such, we assume that $ \Gamma $ contains information about, e.g., the experimental set-up, background knowledge relevant to the system in question, etc. \textcolor{red}{more}, but does not contain the agent's total knowledge of the world. 

Our first step toward modeling explanatory inferences in our meta-language is to represent the subjunctive stability of material inferences. We do so by quantifying over our material consequence relation, $ \nmc $. \newline


\noindent\textbf{Quantified Material Consequence (QMC):}
		\begin{equation}
              \qmc{A}{B}{W} \Longleftrightarrow_{df}
				      \begin{cases}\nonumber
				        1.\,\, W\subseteq\mathcal{P}(\mathcal{L}) & $ and $ \\[3pt] 
						2.\,\, \forall\Delta\in W(\Gamma, A,  \Delta \nmc B ) 
						\end{cases}
		\end{equation}
		

With this definition we now have a handy way of talking about \textit{sets} of material inferences. Note that since $ \emptyset \in W $, the second condition includes $ \Gamma, A \nmc B $. Call this the \textit{base inference} of the set of inferences. Sets of inferences are delimited by the set of sets of sentences of $ \mathcal{L} $ whose members may be added to the premises without impugning the base inference. The resulting set thus contains $ |W| $ many inferences,  and when $ W = \mathcal{P}(\mathcal{L}) $, the consequence relation in $\qmc{A}{B}{W} $ is globally monotonic. When this is the case, we write $ \mqmc[]{}{} $  rather than $ \qmc[]{}{}{ \mathcal{P}(\mathcal{L}) }$.\footnote{The reason for circumscribing these sets of inferences by subsets of $ \mathcal{P}(\mathcal{L}) $ is that atomic sentences that would, by themselves materially defeat an inference if added to the premises, need not defeat that inference if they are add along with other atomic sentences. For instance, the set \{``Liquid $ G $ is acidic'', ``$ G $ turns blue litmus paper white''\} is incoherent but the set \{ ``Chlorine gas is present'', ```Liquid $ G $ is acidic'', ``$ G $ turns blue litmus paper white'' \}  is not.} We may treat $ \qmc{A}{B}{W}  $ as saying that the (base) inference from $ A $ to $ B $ \textit{would} remain materially good for an agent in context $ \Gamma $ even if she \textit{were} to undertake sets of collateral commitments from $ W $. For ease of exposition, we will often refer to $W$ as a set of \textit{subjunctive suppositions}.

Now that we have a way of representing an inference as persisting under subjunctive suppositions, we need a way to depict the full range of an inference's stability---in other words, we need a definition of sturdy inferences. (For the remaining meta-theoretical claims, we omit reference to $\mathcal{L}$ and $\mathcal{P}(\mathcal{L})$ whenever doing so will not mislead the reader.) \newline

\noindent\textbf{Sturdy Material Consequence (SMC):}
		  \begin{equation}
		      \src{A}{B}{W}\Longleftrightarrow_{df}
		      \begin{cases}\nonumber
		        1.\,\, \qmc{A}{B}{W}& $ and $ \\[3pt] 
				2.\,\, \forall W'(\qmc{A}{B}{W'}\Longrightarrow W' \subseteq W)  & $ and $\\[3pt] 
				3.\,\, \nqmc[]{\Gamma}{B}{W} & $ and $\\[3pt]  
		        4.\,\, \forall\Delta(\mqmc{A, \Delta}{\bigperp}\Longrightarrow \Delta \not\in W)

				\end{cases}
		  \end{equation}


The first condition of SMC tells us that the base inference $ \Gamma, A \nmc B $ would be licensed if any of the members of  $W$ were to be added to its premise-set, but the second condition says that $W$ contains \textit{all} those sets of sentences whose addition would not defeat the inference. The third condition prevents the conclusion from simply following from the context alone, while the fourth condition prohibits the elements of $W$ from being logically inconsistent with the premises, thereby ensuring that the conclusion follows non-trivially.\footnote{If SMC4 were not presebnt, $B$ could follow by \textit{Ex Falso Fixo Quodlibet}. See Appendix.}  When the consequence relation $ \src[]{}{}{W} $ holds, we say that the base inference is \textit{sturdy under} $ W $. 

With SRC, we now have the means by which to compare the stability of material inferences that share the same conclusion. This means that we can identify those premises that materially imply a specified conclusion with the greatest subjective stability, thereby capturing the \textit{Superlative Stability} characteristic of explanatory inferences set out above. In order to represent \textit{Difference Making}, however, we need a way to specify the sets of sentences that are incompatible with a particular sentence, $A$, in a particular context, $\Gamma$,  under a set of subjunctive suppositions, $W$. For this, we have QIS.\newline

\noindent\textbf{Quantified Incompatibility Set (QIS):} \hspace{3mm}$ D \in \sris{W}{\Gamma,\,A} \Longleftrightarrow_{df} \,\,\,\qmc{A, D}{\bigperp}{W} $
\newline

The set $  \sris{W}{\Gamma,\,A}  $contains all those formulas that are incompatible with $A$ in context $ \Gamma $ and that would continue to produce materially incoherence were any of the members of $W$ added to it. This definition provides the resources with which to express \textit{Difference Making}. We do so in the third condition of following definition.\newline

\noindent\textbf{Maximally Sturdy Material Consequence (MSMC):}
		\begin{equation}
		   \gsrc{A}{\,B} \Longleftrightarrow_{df} 
		    \begin{cases}\nonumber 
			      1.\,\, \src{A}{B}{W} & $ and $ \\[3pt] 
				  2.\,\, \forall C(C \neq B)\,(\src{C}{B}{W'}\Longrightarrow W'\subseteq W ) & $ and $ \\[3pt] 
				  3.\,\, (\forall D_{\scriptscriptstyle A} \in \sris{W}{\Gamma,\,A}) (\exists!D_{\scriptscriptstyle B} \in \sris{W}{\Gamma,\,B})(\qmc{D_{\scriptscriptstyle A}}{D_{\scriptscriptstyle B}}{W})
			 \end{cases}
		\end{equation}


The MSMC relation is our meta-language expression for explanatory inference. The first condition says that the base inference is sturdy under $W$. The second condition tells us that $W$ is the largest set of subjunctive suppositions under which any sentence from $\mathcal{L}$ materially implies $B$, excluding $B$ itself. For this reason $W $ need not appear on the left-side of the definition. If we think of $ A $ as providing the best explanation of $ B $ and of $ C $ as any less-than-best explanation, then the second condition says that the best explanation is stable under more subjunctive suppositions than any of its suboptimal competitors. The third condition informs us that if any claim incompatible with $A$ were to replace $A$ in the premises, then it would materially imply a unique claim incompatible with $B$, under the subjunctive suppositions in $W$. Since the negation of a sentence can be construed (in an extended language) in terms of quantification over the set of sentences incompatible with that sentence, the third condition entails that if $A$ were not the case, $B$ would not be the case. 

\textcolor{red}{Need a bit more...}






\bibliographystyle{plainnat}
\bibliography{Explanation_bib} 

% % % % % % % % % % % % % % % % % % % % % % % For submission use bib below and paste bibitems % % % % % % % % % % % % % % % % %
%\begin{thebibliography}{19}
%\providecommand{\natexlab}[1]{#1}
%\providecommand{\url}[1]{{#1}}
%\providecommand{\urlprefix}{URL }
%\expandafter\ifx\csname urlstyle\endcsname\relax
%  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
%  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
%  \urlstyle{rm}\Url}\fi
%\providecommand{\eprint}[2][]{\url{#2}}
%
%%\bibitem[{Goldberg(2011)}]{Goldberg2011}
%%Goldberg S (2011) Putting the norm of assertion to work: The case of testimony.
%%  In: Brown J, Cappelen H (eds) Assertion: New Philosophical Essays, Oxford
%%  University Press
%
%
%
%\end{thebibliography}

\end{document}